{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VmNWp-GLrBMD"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B-zzc25UrN4f"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 1: Load the wine dataset\n",
        "wine_data = load_wine()\n",
        "X, y = wine_data.data, wine_data.target\n",
        "\n"
      ],
      "metadata": {
        "id": "6JpqVYQgrOcP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2: Split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "uIdlFLclCvxI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Use RandomizedSearchCV for hyperparameter tuning\n",
        "# Define the hyperparameter grid\n",
        "param_dist = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'splitter': ['best', 'random'],\n",
        "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}"
      ],
      "metadata": {
        "id": "SjPrHSp6C5eT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Decision Tree Classifier\n",
        "dt_classifier = DecisionTreeClassifier()\n",
        "\n",
        "# Use RandomizedSearchCV for hyperparameter tuning\n",
        "random_search = RandomizedSearchCV(dt_classifier, param_distributions=param_dist, n_iter=100, cv=5, scoring='accuracy', n_jobs=-1, random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters found by RandomizedSearchCV\n",
        "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
        "\n",
        "# Step 4: Train the Decision Tree with the best hyperparameters\n",
        "best_dt_classifier = random_search.best_estimator_\n",
        "best_dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_dt_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model's accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Check if the accuracy meets the target of at least 85%\n",
        "if accuracy >= 0.85:\n",
        "    print(\"Achieved the target accuracy!\")\n",
        "else:\n",
        "    print(\"Did not achieve the target accuracy.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQ8xZzhkC-2k",
        "outputId": "d0ccc07e-644c-4802-f3ff-11667ad9dfe2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'splitter': 'best', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 30, 'criterion': 'entropy'}\n",
            "Accuracy: 0.9444444444444444\n",
            "Achieved the target accuracy!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from scipy.stats import mode\n",
        "\n",
        "# Step 1: Create 10 subsets of the training dataset using ShuffleSplit\n",
        "num_subsets = 10\n",
        "shuffle_split = ShuffleSplit(n_splits=num_subsets, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize a list to store the trained decision trees\n",
        "forest_trees = []\n",
        "\n",
        "for train_index, _ in shuffle_split.split(X_train):\n",
        "    # Step 2: Train 1 decision tree on each subset\n",
        "    subset_X_train, subset_y_train = X_train[train_index], y_train[train_index]\n",
        "\n",
        "    # Create a Decision Tree Classifier with the best hyperparameters\n",
        "    tree_classifier = DecisionTreeClassifier(**random_search.best_params_)\n",
        "\n",
        "    # Train the decision tree on the subset\n",
        "    tree_classifier.fit(subset_X_train, subset_y_train)\n",
        "\n",
        "    # Add the trained tree to the list\n",
        "    forest_trees.append(tree_classifier)\n",
        "\n",
        "# Step 3: Evaluate all the trees on the test dataset\n",
        "# Initialize an array to store predictions from each tree\n",
        "forest_predictions = []\n",
        "\n",
        "# Make predictions for each tree in the forest\n",
        "for tree in forest_trees:\n",
        "    tree_pred = tree.predict(X_test)\n",
        "    forest_predictions.append(tree_pred)\n",
        "\n",
        "# Combine the predictions using majority voting (mode)\n",
        "ensemble_predictions = np.array(forest_predictions).T\n",
        "final_predictions = mode(ensemble_predictions, axis=1).mode.flatten()\n",
        "\n",
        "# Evaluate the performance of the random forest\n",
        "forest_accuracy = accuracy_score(y_test, final_predictions)\n",
        "print(\"Random Forest Accuracy:\", forest_accuracy)\n",
        "\n",
        "# Compare with the previous Decision Tree accuracy\n",
        "print(\"Previous Decision Tree Accuracy:\", accuracy)\n",
        "\n",
        "# Check if the random forest performs better than the previous Decision Tree\n",
        "if forest_accuracy > accuracy:\n",
        "    print(\"Random Forest performs better than the previous Decision Tree.\")\n",
        "else:\n",
        "    print(\"Random Forest does not outperform the previous Decision Tree.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6L4id-pFDCGV",
        "outputId": "2a35f162-c745-46ee-dcac-fa44c279fc42"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.9444444444444444\n",
            "Previous Decision Tree Accuracy: 0.9444444444444444\n",
            "Random Forest does not outperform the previous Decision Tree.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MC_tDjQWD-M1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}